{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis\n",
    "\n",
    "We're able to crawl for headlines from various collections but I don't yet know how to see which publishers are available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fundus import PublisherCollection, Crawler, NewsMap\n",
    "from flair.data import Sentence\n",
    "from flair.models import TextClassifier\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article:\n",
      "- Title: \"EU Officials Will Claim Ignorance of Israel’s War Crimes. This Leaked [...]\"\n",
      "- Text:  \"European Union foreign ministers rebuffed a call to end arms sales to Israel\n",
      "          last month, despite mounting evidence of war crimes — and, [...]\"\n",
      "- URL:    https://theintercept.com/2024/12/23/eu-report-israel-war-crimes-complicity/\n",
      "- From:   The Intercept (2024-12-23 15:34)\n",
      "Fundus-Article:\n",
      "- Title: \"AP News Quiz - Dec. 23, 2024\"\n",
      "- Text:  \"EXPLORE OTHER QUIZZES\"\n",
      "- URL:    https://apnews.com/quiz-test-your-news-i.q.-241223\n",
      "- From:   Associated Press News (2024-12-23 10:52)\n"
     ]
    }
   ],
   "source": [
    "# initialize the crawler for news publishers based in the US\n",
    "crawler = Crawler(PublisherCollection.us)\n",
    "\n",
    "# crawl 2 articles and print\n",
    "for article in crawler.crawl(max_articles=2):\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AP News Quiz - Dec. 23, 2024\n",
      "so\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'EXPLORE OTHER QUIZZES'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(article.title)\n",
    "print(article.lang) # detects language of article\n",
    "article.plaintext\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article:\n",
      "- Title: \"The New “Nosferatu” Drains the Life from its Predecessor\"\n",
      "- Text:  \"Robert Eggers’s take expands significantly on the 1922 classic—and makes a\n",
      "          pivotal change, with sickening implications.  Robert Eggers’s [...]\"\n",
      "- URL:    https://www.newyorker.com/culture/the-front-row/the-new-nosferatu-drains-the-life-from-its-predecessor\n",
      "- From:   The New Yorker (2024-12-23 11:19)\n",
      "Fundus-Article:\n",
      "- Title: \"“Black Doves” Offers a Sentimental Spin on the Spy Genre\"\n",
      "- Text:  \"The Keira Knightley- and Ben Whishaw-led Netflix series eventually snares its\n",
      "          protagonists in a traditional espionage plot—but it’s most [...]\"\n",
      "- URL:    https://www.newyorker.com/magazine/2024/12/30/black-doves-tv-review-netflix\n",
      "- From:   The New Yorker (2024-12-23 06:00)\n"
     ]
    }
   ],
   "source": [
    "# initialize the crawler for The New Yorker\n",
    "crawler = Crawler(PublisherCollection.us.TheNewYorker)\n",
    "\n",
    "# crawl 2 articles and print\n",
    "for article in crawler.crawl(max_articles=2):\n",
    "    print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crawl_headlines(crawlers, name_of_publishers, article_number=20):\n",
    "    \"\"\"Crawls headlines from a list of crawlers for specified publishers.\n",
    "\n",
    "    This function takes three arguments:\n",
    "        - crawlers: A list of web crawlers, each responsible for a specific publisher.\n",
    "        - name_of_publishers: A list of publisher names corresponding to the crawlers.\n",
    "        - article_number (optional): The maximum number of articles to crawl per publisher. Defaults to 20.\n",
    "\n",
    "    It returns a dictionary where the keys are publisher names and the values are lists of headlines crawled from those publishers.\n",
    "    \"\"\"\n",
    "\n",
    "    headlines = {}\n",
    "\n",
    "    for crawler, name_of_publisher in zip(crawlers, name_of_publishers):\n",
    "        \"\"\"Iterates through crawlers and corresponding publisher names.\"\"\"\n",
    "\n",
    "        publisher = []\n",
    "\n",
    "        for article in tqdm(crawler.crawl(max_articles=article_number)):\n",
    "            \"\"\"Crawls the title of articles from the current crawler up to the specified article_number.\"\"\"\n",
    "            publisher.append(article.title)\n",
    "\n",
    "        headlines[name_of_publisher] = publisher\n",
    "\n",
    "    return headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:13,  1.39s/it]\n",
      "10it [00:18,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "crawler1 = Crawler(PublisherCollection.us.CNBC)\n",
    "crawler2 = Crawler(PublisherCollection.us.TheNation)\n",
    "\n",
    "crawlers = [crawler1, crawler2]\n",
    "names_of_publishers = [\"CNBC\", \"The Nation\"]\n",
    "headlines = crawl_headlines(crawlers, names_of_publishers, article_number=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'CNBC': [\"Silicon Valley's White House influence grows as Trump taps tech execs for key roles\",\n",
       "  'Biden administration withdraws student loan forgiveness plans. What borrowers should know',\n",
       "  'U.S. sues Walmart, Branch Messenger over payment accounts for delivery drivers',\n",
       "  \"Savannah James' worst money mistake still gives her the 'heebie jeebies': It was 'a substantial amount, I'm still stressed out'\",\n",
       "  'I asked a 105-year-old when middle age starts: Her answer delighted me—and made me feel better about turning 40',\n",
       "  \"House Ethics panel finds Matt Gaetz had sex with 17-year-old, 'regularly' paid for sex\",\n",
       "  'Here are our top 10 things to watch in the stock market Monday',\n",
       "  'Nordstrom to go private in $6.25 billion deal with founding family, Mexican retailer',\n",
       "  \"This career coach 'always' negotiates for more PTO—her top 3 tips for making the ask\",\n",
       "  \"Charge card vs. credit card: What's the difference?\"],\n",
       " 'The Nation': ['A Far-Right Attacker Kills 5 in a Christmas Market. The German Far Right Takes Advantage.',\n",
       "  'Novelist on a Deadline: Barry Malzberg, 1939–2024',\n",
       "  'These Progressive Will Guide Us Through the Darkness',\n",
       "  'The Best Albums of 2024',\n",
       "  'A Stunning Year for Student Journalism',\n",
       "  'The Spending Fiasco Was a Preview of the Trump-Musk Administration',\n",
       "  'When the Feds Are Still Watching',\n",
       "  'My 2025 Project: Starting a New Column, “Hiding in Plain Sight”',\n",
       "  'The Billionaire Who Stole Christmas',\n",
       "  'The Downsides of the Wind Energy Boom']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(publisher_headlines):\n",
    "    \"\"\"Predicts sentiment labels for headlines from each publisher.\n",
    "\n",
    "    This function takes a dictionary `publisher_headlines` as input. \n",
    "    The dictionary keys are publisher names and the values are lists of headlines.\n",
    "\n",
    "    The function performs sentiment analysis on each headline and stores the predicted labels \n",
    "    in a new dictionary with the same publisher names as keys.\n",
    "\n",
    "    It returns a dictionary where the keys are publisher names and the values are lists of predicted sentiment labels \n",
    "    for the corresponding headlines.\n",
    "    \"\"\"\n",
    "\n",
    "    sentiments_per_publisher = {}\n",
    "\n",
    "    # Load a sentiment classifier (TextClassifier likely refers to a custom class or library)\n",
    "    tagger = TextClassifier.load('sentiment')  \n",
    "\n",
    "    for key, values in publisher_headlines.items():\n",
    "        \"\"\"Iterates through each publisher and its corresponding headlines.\"\"\"\n",
    "\n",
    "        temp = []\n",
    "        for value in values:\n",
    "            \"\"\"Iterates through each headline for the current publisher\"\"\"\n",
    "            sentence = Sentence(value)  # Create a Sentence object (likely custom class) for the headline\n",
    "            tagger.predict(sentence)    # Predict sentiment label for the sentence using the loaded classifier\n",
    "            temp.append(sentence.get_label().value)  # Append the predicted label value to a temporary list\n",
    "\n",
    "        sentiments_per_publisher[key] = temp  # Add the list of predicted labels for the publisher to the result dictionary\n",
    "\n",
    "    return sentiments_per_publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiments_per_publisher=predict_labels(headlines) # getting sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentiments_per_publisher['CNBC'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(sentiments_per_publisher, number_of_articles=20):\n",
    "    \"\"\"\n",
    "    This function iterates over a dictionary of sentiments per publisher and prints statistics about the sentiment distribution.\n",
    "\n",
    "    Args:\n",
    "        sentiments_per_publisher (dict): A dictionary where keys are publishers and values are lists of sentiment labels for their articles.\n",
    "        number_of_articles (int, optional): The number of articles to consider when calculating statistics. Defaults to 20.\n",
    "    \"\"\"\n",
    "\n",
    "    for keys, values in sentiments_per_publisher.items():\n",
    "        \"\"\"\n",
    "        Iterates over each publisher and their corresponding sentiment labels.\n",
    "        \"\"\"\n",
    "\n",
    "        positive = 0\n",
    "        negative = 0\n",
    "        something_else = 0\n",
    "        for value in values:\n",
    "            \"\"\"\n",
    "            Iterates over each sentiment label for the current publisher.\n",
    "            \"\"\"\n",
    "\n",
    "            if value == \"POSITIVE\":\n",
    "                positive += 1\n",
    "            elif value == \"NEGATIVE\":\n",
    "                negative += 1\n",
    "            else:\n",
    "                something_else += 1\n",
    "        print(f\"{keys} has {positive} positive and {negative} negative headlines out of {number_of_articles}.\")\n",
    "        if something_else >= 1:\n",
    "            print(f\"If something got wrong then it has {something_else} something_else headlines.\")\n",
    "        print()\n",
    "\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNBC has 4 positive and 6 negative headlines out of 10.\n",
      "\n",
      "The Nation has 6 positive and 4 negative headlines out of 10.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_statistics(sentiments_per_publisher,number_of_articles = len(sentiments_per_publisher['CNBC']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A Far-Right Attacker Kills 5 in a Christmas Market. The German Far Right Takes Advantage.',\n",
       " 'Novelist on a Deadline: Barry Malzberg, 1939–2024',\n",
       " 'These Progressive Will Guide Us Through the Darkness',\n",
       " 'The Best Albums of 2024',\n",
       " 'A Stunning Year for Student Journalism',\n",
       " 'The Spending Fiasco Was a Preview of the Trump-Musk Administration',\n",
       " 'When the Feds Are Still Watching',\n",
       " 'My 2025 Project: Starting a New Column, “Hiding in Plain Sight”',\n",
       " 'The Billionaire Who Stole Christmas',\n",
       " 'The Downsides of the Wind Energy Boom']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yep, many of these titles sound negative to me\n",
    "headlines['The Nation']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to filter by topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "keywords = ['market','stock']\n",
    "def body_filter(extracted: Dict[str, Any]) -> bool:\n",
    "    if body := extracted.get(\"body\"):\n",
    "        for word in keywords:\n",
    "            if word in str(body).casefold():\n",
    "                return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fundus-Article:\n",
      "- Title: \"This Was the Year Elon Musk Took Over Politics\"\n",
      "- Text:  \"The American public elected Donald Trump to run the federal government. His\n",
      "          erratic patron seems to think the job is also his.  Donald Trump [...]\"\n",
      "- URL:    https://www.wired.com/story/the-year-elon-musk-took-over-politics/\n",
      "- From:   Wired (2024-12-23 11:16)\n",
      "Fundus-Article:\n",
      "- Title: \"Honda and Nissan plan major merger focused on 'intelligence and electrification'\"\n",
      "- Text:  \"Japanese car giants Honda and Nissan are working out the details of a major\n",
      "          merger that could create the world’s third-largest automaker, as [...]\"\n",
      "- URL:    https://techcrunch.com/2024/12/23/honda-and-nissan-plan-major-merger-focused-on-intelligence-and-electrification/\n",
      "- From:   TechCrunch (2024-12-23 16:07)\n"
     ]
    }
   ],
   "source": [
    "crawler = Crawler(PublisherCollection.us)\n",
    "\n",
    "for us_themed_article in crawler.crawl(max_articles=2,only_complete=body_filter):\n",
    "    print(us_themed_article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "erdos_fall_2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
